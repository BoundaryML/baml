---
title: Prompting in BAML
---

<Note>
We recommend reading the [installation](/) instructions first
</Note>

BAML helps you write prompts as `functions` that you can use in your application. The BAML compiler translates these to REST requests to call the LLM provider endpoints, and parse the output to get the **guaranteed output type** you want.




Here is a simple BAML function to extract a resume. 
- The **input is a chunk of resume_text**, and 
- the **output is an actual `Resume` class**. 

A prompt is configured with an LLM client, and is written using Jinja strings. [Read more about prompt syntax](/learn/prompt-syntax/what-is-jinja.mdx)

```rust BAML
class Resume {
  name string
  education Education[] @description("Extract in the same order listed")
  skills string[] @description("Only include programming languages")
}

class Education {
  school string
  degree string
  year int
}

function ExtractResume(resume_text: string) -> Resume {
  client GPT4Turbo
  // The prompt uses Jinja syntax. Change the models or this text and watch the prompt preview change!
  prompt #"
    Parse the following resume and return a structured representation of the data in the schema below.

    Resume:
    ---
    {{ resume_text }}
    ---

    {# special macro to print the output instructions. #}
    {{ ctx.output_format }}

    JSON:
  "#
}

test TestExtractResume {
  args {
    resume_text "Jason Doe\nPython, Rust\nUniversity of California, Berkeley, B.S.\nin Computer Science, 2020\nAlso an expert in Tableau, SQL, and C++"
  }
}
```

If you are using VSCode extension, you can see the how the prompt is rendered, and what `ctx.output_format` is:

<img src="/assets/vscode/extract-resume-prompt-preview.png" alt="Prompt preview" />

And you can dive even deeper to see the **Raw CURL request** BAML will make to the LLM provider:

<img src="/assets/vscode/curl-preview.png" alt="Raw CURL request" />

<Warning>
Always include the `{{ ctx.output_format }}` macro in your prompt. This injects your output schema into the prompt, which helps the LLM output the right thing. You can also [customize what it prints](/reference).

One of our design philosophies is to never hide the prompt from you. You control and can always see the entire prompt.
</Warning>

## Calling the function
Recall that BAML will generate a `baml_client` directory in the language of your choice using the parameters in your `generator` config. Do not modify these contents, as they're autogenerated.

```baml some-baml-file.baml
generator target {
    // Valid values: "python/pydantic", "typescript", "ruby/sorbet"
    output_type "python/pydantic"
    // Where the generated code will be saved (relative to baml_src/)
    output_dir "../"
    // Version of runtime to generate code for (should match the package @boundaryml/baml version)
    version "0.62.0"
}
```

A potential setup looks like this:
<img src="/assets/vscode/baml-client.png" alt="Generated client" width={300} />

This client will contain the same function as you defined in your BAML file, and you can call it like any other function.

BAML's fuzzy parser will fix any common json mistakes LLMs make.

<CodeBlocks>
```python python
from baml_client import b
from baml_client.types import Resume

async def main():
resume_text = """Jason Doe\nPython, Rust\nUniversity of California, Berkeley, B.S.\nin Computer Science, 2020\nAlso an expert in Tableau, SQL, and C++\n"""

    # this function comes from the autogenerated "baml_client".
    # It calls the LLM you specified and handles the parsing.
    resume = await b.ExtractResume(resume_text)

    # Fully type-checked and validated!
    assert isinstance(resume, Resume)

```

```typescript typescript
import b from 'baml_client'

async function main() {
  const resume_text = `Jason Doe\nPython, Rust\nUniversity of California, Berkeley, B.S.\nin Computer Science, 2020\nAlso an expert in Tableau, SQL, and C++`

  // this function comes from the autogenerated "baml_client".
  // It calls the LLM you specified and handles the parsing.
  const resume = await b.ExtractResume(resume_text)

  // Fully type-checked and validated!
  resume.name === 'Jason Doe'
}
```

```ruby ruby

require_relative "baml_client/client"
b = Baml.Client

# Note this is not async
res = b.TestFnNamedArgsSingleClass(
    myArg: Baml::Types::Resume.new(
        key: "key",
        key_two: true,
        key_three: 52,
    )
)
```

</CodeBlocks>

## Complex Inputs and Examples

Your BAML types can be used as inputs to other BAML functions (or even Python/TS/Ruby code).

For example, we can inject `Resume` object as input into a new BAML function called `AnalyzeResume`.

<CodeBlocks>
```python Python
from baml_client.types import Resume
from baml_client import b
...
  await b.AnalyzeResume(
    Resume(name="Mark", education=[...]))

````

```typescript typescript
import { Resume, b } from "baml_client"

...
  await b.AnalyzeResume({
    name: "Mark",
    education: [...]
  })
````

```ruby Ruby
require_relative "baml_client/client"
b = Baml.Client
...
res = b.AnalyzeResume(
  myArg: Baml::Types::Resume.new(
      name: "key",
      education: [...]
  )
)
```

</CodeBlocks>


Checkout [PromptFiddle](https://promptfiddle.com) to see various interactive BAML function examples or view the [example projects](/examples)
