client<llm> MyClient {
  provider baml-openai-chat
  options {
    model gpt-3.5-turbo
    max_tokens 100
  }
}