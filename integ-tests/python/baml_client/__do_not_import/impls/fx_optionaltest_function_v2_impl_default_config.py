# This file is generated by the BAML compiler.
# Do not edit this file directly.
# Instead, edit the BAML files and recompile.

# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

from ..clients.client_gpt35 import GPT35
from ..functions.fx_optionaltest_function_v2 import BAMLOptionalTest_Function_V2
from ..types.classes.cls_optionaltest_prop1v2 import OptionalTest_Prop1v2
from ..types.classes.cls_optionaltest_returntypev2 import OptionalTest_ReturnTypev2
from ..types.enums.enm_optionaltest_categorytypev2 import OptionalTest_CategoryTypev2
from ..types.partial.classes.cls_optionaltest_prop1v2 import PartialOptionalTest_Prop1v2
from ..types.partial.classes.cls_optionaltest_returntypev2 import PartialOptionalTest_ReturnTypev2
from baml_core.jinja.render_prompt import RenderData
from baml_core.provider_manager.llm_response import LLMResponse
from baml_core.stream import AsyncStream
from baml_lib._impl.deserializer import Deserializer
from typing import List, Optional


import typing
# Impl: default_config
# Client: GPT35
# An implementation of OptionalTest_Function_V2.

__prompt_template = """\


Return a JSON blob with this schema: 
{#print_type(output)}
Here's a list of values you can use for
{#print_enum(OptionalTest_CategoryTypev2)}

JSON:\
"""

# We ignore the type here because baml does some type magic to make this work
# for inline SpecialForms like Optional, Union, List.
__deserializer = Deserializer[List[Optional[OptionalTest_ReturnTypev2]]](List[Optional[OptionalTest_ReturnTypev2]])  # type: ignore

# Add a deserializer that handles stream responses, which are all Partial types
__partial_deserializer = Deserializer[List[Optional[OptionalTest_ReturnTypev2]]](List[Optional[OptionalTest_ReturnTypev2]])  # type: ignore

__output_format = """
({
  "omega_1": {
    "omega_a": string,
    "omega_b": int
  } | null,
  "omega_2": string | null,
  "omega_3": ("OptionalTest_CategoryTypev2 as string" | null)[]
} | null)[]

OptionalTest_CategoryTypev2
---
Aleph
Beta
Gamma
""".strip()

__template_macros = [
]


async def default_config(*, input: str) -> List[Optional[OptionalTest_ReturnTypev2]]:
    response = await GPT35.run_jinja_template(
        jinja_template=__prompt_template,
        output_format=__output_format, template_macros=__template_macros,
        args=dict(input=input)
    )
    deserialized = __deserializer.from_string(response.generated)
    return deserialized


def default_config_stream(*, input: str
) -> AsyncStream[List[Optional[OptionalTest_ReturnTypev2]], List[Optional[OptionalTest_ReturnTypev2]]]:
    def run_prompt() -> typing.AsyncIterator[LLMResponse]:
        raw_stream = GPT35.run_jinja_template_stream(
            jinja_template=__prompt_template,
            output_format=__output_format, template_macros=__template_macros,
            args=dict(input=input)
        )
        return raw_stream
    stream = AsyncStream(stream_cb=run_prompt, partial_deserializer=__partial_deserializer, final_deserializer=__deserializer)
    return stream

BAMLOptionalTest_Function_V2.register_impl("default_config")(default_config, default_config_stream)