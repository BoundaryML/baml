# This file is generated by the BAML compiler.
# Do not edit this file directly.
# Instead, edit the BAML files and recompile.

# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

from ..clients.client_claude import Claude
from ..functions.fx_optionaltest_function import BAMLOptionalTest_Function
from ..types.classes.cls_optionaltest_prop1 import OptionalTest_Prop1
from ..types.classes.cls_optionaltest_returntype import OptionalTest_ReturnType
from ..types.enums.enm_optionaltest_categorytype import OptionalTest_CategoryType
from ..types.partial.classes.cls_optionaltest_prop1 import PartialOptionalTest_Prop1
from ..types.partial.classes.cls_optionaltest_returntype import PartialOptionalTest_ReturnType
from baml_core.provider_manager.llm_provider_base import LLMChatMessage
from baml_core.provider_manager.llm_response import LLMResponse
from baml_core.stream import AsyncStream
from baml_lib._impl.deserializer import Deserializer
from typing import List, Optional


import typing
# Impl: v1
# Client: Claude
# An implementation of OptionalTest_Function.

__prompt_template: List[LLMChatMessage] = [
{
    "role": "user",
    "content": """\
Return a JSON blob with this schema: 
({
  "omega_1": {
    "omega_a": string,
    "omega_b": int
  } | null,
  "omega_2": string | null,
  "omega_3": ("OptionalTest_CategoryType as string" | null)[]
} | null)[]

Here's a list of values you can use for
OptionalTest_CategoryType
---
Aleph
Beta
Gamma

JSON:\
"""
}

]

__input_replacers = {
}


# We ignore the type here because baml does some type magic to make this work
# for inline SpecialForms like Optional, Union, List.
__deserializer = Deserializer[List[Optional[OptionalTest_ReturnType]]](List[Optional[OptionalTest_ReturnType]])  # type: ignore

# Add a deserializer that handles stream responses, which are all Partial types
__partial_deserializer = Deserializer[List[Optional[OptionalTest_ReturnType]]](List[Optional[OptionalTest_ReturnType]])  # type: ignore







async def v1(arg: str, /) -> List[Optional[OptionalTest_ReturnType]]:
    response = await Claude.run_chat_template(__prompt_template, replacers=__input_replacers, params=dict(arg=arg))
    deserialized = __deserializer.from_string(response.generated)
    return deserialized


def v1_stream(arg: str, /) -> AsyncStream[List[Optional[OptionalTest_ReturnType]], List[Optional[OptionalTest_ReturnType]]]:
    def run_prompt() -> typing.AsyncIterator[LLMResponse]:
        raw_stream = Claude.run_chat_template_stream(__prompt_template, replacers=__input_replacers, params=dict(arg=arg))
        return raw_stream
    stream = AsyncStream(stream_cb=run_prompt, partial_deserializer=__partial_deserializer, final_deserializer=__deserializer)
    return stream

BAMLOptionalTest_Function.register_impl("v1")(v1, v1_stream)