# This file is generated by the BAML compiler.
# Do not edit this file directly.
# Instead, edit the BAML files and recompile.

# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

from ..clients.client_azure_gpt4 import AZURE_GPT4
from ..functions.fx_classifytool import BAMLClassifyTool
from ..types.classes.cls_classifyresponse import ClassifyResponse
from ..types.enums.enm_tool import Tool
from ..types.partial.classes.cls_classifyresponse import PartialClassifyResponse
from baml_core.stream import AsyncStream
from baml_lib._impl.deserializer import Deserializer


import typing
# Impl: v1
# Client: AZURE_GPT4
# An implementation of ClassifyTool.

__prompt_template = """\

{query}

UserContext:
{context}

tool
---
k1: Use this tool if the user is asking to compute something
k2: Use this tool if the user is asking to draw something
k3: Use this tool if the user is asking to generate text 

Use this output format:
{
  // Any number of tools the user may want to use
  "tool": "tool as string"[],
  // This is the assistance reponse
  "foo": string
}

JSON:\
"""

__input_replacers = {
    "{context}",
    "{query}"
}


# We ignore the type here because baml does some type magic to make this work
# for inline SpecialForms like Optional, Union, List.
__deserializer = Deserializer[ClassifyResponse](ClassifyResponse)  # type: ignore
__deserializer.overload("ClassifyResponse", {"foo": "assistant_response"})

# Add a deserializer that handles stream responses, which are all Partial types
__partial_deserializer = Deserializer[PartialClassifyResponse](PartialClassifyResponse)  # type: ignore
__partial_deserializer.overload("ClassifyResponse", {"foo": "assistant_response"})







async def v1(*, query: str, context: str) -> ClassifyResponse:
    response = await AZURE_GPT4.run_prompt_template(template=__prompt_template, replacers=__input_replacers, params=dict(query=query, context=context))
    deserialized = __deserializer.from_string(response.generated)
    return deserialized


def v1_stream(*, query: str, context: str
) -> AsyncStream[ClassifyResponse, PartialClassifyResponse]:

    raw_stream = AZURE_GPT4.run_prompt_template_stream(template=__prompt_template, replacers=__input_replacers, params=dict(query=query, context=context))
    stream = AsyncStream(raw_stream, __partial_deserializer, __deserializer)
    return stream

BAMLClassifyTool.register_impl("v1")(v1, v1_stream)