---
title: What is BAML?
"og:description": Boundary is the test-driven toolkit for AI engineers.
"og:image": https://mintlify.s3-us-west-1.amazonaws.com/gloo/images/v3/AITeam.png
"twitter:image": https://mintlify.s3-us-west-1.amazonaws.com/gloo/images/v3/AITeam.png
---


# BAML

BAML is a config file format for declaring LLM functions that you can then use in TypeScript or Python.

With BAML you can Classify or Extract any structured data using Anthropic, OpenAI or local models (using Ollama)

BAML comes with a **VSCode Playground**, which allows you to test prompts instantly with any LLM, without ever leaving VSCode.

<img src="/images/v3/testing_2.gif" />

Here's a 1-min video on how **BAML works seamlessly with Python (or TypeScript)** to get structured outputs from LLMs:  

<iframe width="560" height="315" src="https://www.youtube.com/embed/dpEvGrVJJng?si=6CPRTxil8WjQ_t5w" title="YouTube video player" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowFullScreen></iframe>

Here’s a `.baml` AI function:

```rust example.baml
// example.baml
class Resume {
  name string
  skills string[]
}

function ExtractResume {
  input (resume_text: string)
  output Resume[]
}

impl<llm, ExtractResume> version1 {
  client GPT4Client // client definition not shown
  prompt #"
    Parse the following resume and return a structured representation of the data in the schema below.

    Resume:
    ---
    {#input.resume_text}
    ---
    Output in this JSON format:
    {#print_type(output)}

    Output JSON:
  "#
}
```

**BAML compiles to fully typed Python and TypeScript**. No matter how you change the prompt, or the LLM model, or fail-overs, the python code doesn’t change — unless you change your AI function’s signature.

The BAML compiler generates all the parsing boilerplate you need. No need to parse with `json.loads` ever again.

<CodeGroup>
```python Python
from baml_client import baml as b

async def main():
  resume = await b.ExtractResume(resume_text="""John Doe
Python, Rust
University of California, Berkeley, B.S.
in Computer Science, 2020""")

  assert resume.name == "John Doe"
```

```typescript TypeScript
import b from "@/baml_client";

const main = async () => {
  const verb_list = await b.ExtractVerbs({
    resume: `John Doe
Python, Rust
University of California, Berkeley, B.S.
in Computer Science, 2020
`
  });

  assert resume.name === 'John Doe';
};
```
</CodeGroup>

BAML can be deployed to any container, with only a single package dependency required (`e.g. pip install baml`). 
{/* [Learn more](/v3/home/deployment) */}

<Frame caption="BAML VSCode Playground">
<img src="/images/v3/baml_playground.png" />
</Frame>

## Getting Started

Start by [installing BAML](/v3/home/installation) and reading our [Hello World Tutorial](/v3/guides/hello_world/level0). 

The VSCode extension provides auto-compiling on save, a realtime preview of the full prompt, syntax highlighting and great errors — every syntax error recommends a fix. 

Making BAML easy to read and write is our core design philosophy.

#### What you get out-of-the-box
- **Typed Python/Typescript support**
- **VSCode Playground** -- see the full prompt and run tests
- **Better code organization** — no scattered jinja templates or yaml files
- **Its fast!**  -- BAML compiles into PY and TS in less than 50ms (We ❤️ Rust)
- **Full integration with** **Boundary Studio** -- our observability dashboard
    - Turn live production data into a test-case with one click!
- **Get structured responses,** 11 natively supported  types, including custom classes
- **Hallucination Checks** -- when LLMs return something unexpected, we throw an exception

- And best of all, **everything lives in your codebase.**

    
