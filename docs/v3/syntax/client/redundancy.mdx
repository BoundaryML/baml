---
title: Fallbacks/Redundancy
---

Many LLMs are subject to fail due to transient errors. Setting up a fallback allows you to switch to a different LLM when prior LLMs fail (e.g. outage, high latency, rate limits, etc).

To accomplish this, instead of new syntax, you can simple define a `client<llm>` using a `baml-fallback` provider.

The `baml-fallback` provider takes a `strategy` option, which is a list of `client<llm>`s to try in order. If the first client fails, the second client is tried, and so on.

```rust
client<llm> MySafeClient {
    provider baml-fallback
    options {
      // First try GPT4 client, if it fails, try GPT35 client.
      strategy [
        GPT4,
        GPT35
        // If you had more clients, you could add them here.
        // Anthropic
      ]
  }
}

client<llm> GPT4 {
    provider baml-openai-chat
    options {
      // ...
    }
}

client<llm> GPT35 {
    provider baml-openai-chat
    options {
      // ...
    }
}
```

## Conditions for fallback

By default, the fallback is triggered on any error.

However, you can customize this behavior for each client in the strategy (except the first).

```rust
client<llm> MySafeClient {
    provider baml-fallback
    options {
      // First try GPT4 client, if it fails, try GPT35 client.
      strategy [
        GPT4,
        {
          // If GPT4 fails with a 429, 500, 503 try AZUREGPT4
          on_status_code [429, 500, 503]
          client AZUREGPT4
        },
        // As a last resort, always try GPT35
        GPT35
      ]
  }
}
```

Errors codes are:
| Name | Error Code |
| ----------------- | -------------------- |
| BAD_REQUEST | 400 |
| UNAUTHORIZED | 401 |
| FORBIDDEN | 403 |
| NOT_FOUND | 404 |
| RATE_LIMITED | 429 |
| INTERNAL_ERROR | 500 |
| SERVICE_UNAVAILABLE | 503 |
| UNKNOWN | 1 |
