---
title: openai
slug: docs/snippets/clients/providers/openai
---

The `openai` provider supports the OpenAI `/chat` endpoint, setting OpenAI-specific
default configuration options.

<Tip>
  For Azure, we recommend using [`azure-openai`](azure) instead.

  For all other OpenAI-compatible API providers, such as Groq, HuggingFace,
  Ollama, OpenRouter, Together AI, and others, we recommend using
 [`openai-generic`](openai-generic) instead.
</Tip>

Example:

```baml BAML
client<llm> MyClient {
  provider "openai"
  options {
    api_key env.MY_OPENAI_KEY
    model "gpt-3.5-turbo"
    temperature 0.1
  }
}
```

The options are passed through directly to the API, barring a few. Here's a shorthand of the options:

## Non-forwarded options

<ParamField path="api_key" type="string" default="env.OPENAI_API_KEY">
  Will be used to build the `Authorization` header, like so: `Authorization: Bearer $api_key`

  **Default: `env.OPENAI_API_KEY`**
</ParamField>

<ParamField path="base_url" type="string">
  The base URL for the API.
  
  **Default: `https://api.openai.com/v1`**
</ParamField>

<ParamField path="default_role" type="string">
  The default role for any prompts that don't specify a role.
  
  We don't do any validation of this field, so you can pass any string you wish.
  
  **Default: `system`**
</ParamField>

<ParamField path="headers" type="object">
  Additional headers to send with the request.

Example:

```baml BAML
client<llm> MyClient {
  provider openai
  options {
    api_key env.MY_OPENAI_KEY
    model "gpt-3.5-turbo"
    headers {
      "X-My-Header" "my-value"
    }
  }
}
```

</ParamField>

<Markdown src="../../../../snippets/finish-reason.mdx" />
<Markdown src="../../../../snippets/allowed-role-metadata-basic.mdx" />

## Forwarded options

<ParamField
   path="messages"
   type="DO NOT USE"
>
  BAML will auto construct this field for you from the prompt
</ParamField>
<ParamField
   path="stream"
   type="DO NOT USE"
>
  BAML will auto construct this field for you based on how you call the client in your code
</ParamField>
<ParamField
  path="model"
  type="string"
>
  The model to use.

| Model           | Description                    |
| --------------- | ------------------------------ |
| `gpt-3.5-turbo` | Fastest                        |
| `gpt-4o`        | Fast + text + image            |
| `gpt-4-turbo`   | Smartest + text + image + code |
| `gpt-4o-mini`   | Cheapest + text + image        |

See openai docs for the list of openai models. You can pass any model name you wish, we will not check if it exists.

</ParamField>

For all other options, see the [official OpenAI API documentation](https://platform.openai.com/docs/api-reference/chat/create).
