---
title: "Language Tour"
---

Below is an overview of the syntax of BAML as well as the LLM-specific functionality it enables. For a more detailed reference see the [Language Reference](ref/class).

See [why BAML](/v2/mdx/overview#why-use-baml-vs-other-libraries) for a discussion of the motivation behind BAML.

### Strings
BAML allows strings as first-class citizens, to support more struggle-free prompt engineering.

This is a valid **inline string**, which is surrounded by double quotes.
```llvm
"Hello World"
```
If a string is on multiple lines, it must be surrounded by #" and "#. This is called a **block string**.
```llvm 
#"
Hello
World
"#
```
Block strings are automatically dedented and stripped of the first and last newline. This means that the following will render the same thing as above
```llvm
#"
    Hello
    World
"#
```

BAML also supports simple **unquoted in-line** strings. The string below is valid!
```
Hello World
```
Unquoted strings **may not** have any of the following since they are reserved characters (note this may change in the future):
- Quotes "double" or 'single'
- At-signs    @
- Curlies     {}
- hashtags    #
- Parentheses ()
- Brackets    []
- commas      ,
- newlines


### Comments
This is a commment:
```rust
// hello there!
```

But you can also have **comments in block strings**! This is useful for adding documentation to your LLM prompts as below.
```llvm
#"
Hello world.
{// this won't show up in the prompt! //}
Please {// 'please' works best, don't ask.. //} enter your name:
"#
```
BAML trims the whitespace from the side of a comment block with the least amount of empty space.

**Comments can be multiline**
```rust
#"
  {//
    some giant
    comment
  //}
"#
```


### Classes 
In BAML a **Class** defines a complex type. In the context of LLMs, classes describe the type of the variables you can inject into prompts. This is sort of equivalent to a Pydantic model in Python.

```llvm
class Person {
    firstName String
}
```
Note there are no only spaces between the property and the type. No colons, nor equal signs.

### Enums
Enums are useful for classification tasks. BAML has helper functions that can help you serialize an enum into your prompt in a neatly formatted list (more on that later).
```llvm
enum MyEnum {
    GPT3
    GPT4
}
```

### Types
BAML supports the following types:
* strings   |   `string`
* integers  |  `int`
* booleans  |  `bool`
* Array     |  `[]`
* Another class

```llvm
class Person {
    firstName String
    age int
    isCool bool
    friends Person[]
}
```

See the [Language Reference](ref/type) for more details on complex types, like optionals.

### booleans
BAML supports booleans. They are either `true` or `false`. Note that they are not quoted.

### Dictionaries / configuration
BAML dictionaries have no spaces between elements. Configs are separated by a new line.
```llvm

  ...
    options {
      temperature 0.9
      inline_string "hi there!"
      model_name gpt-3.5-turbo // an unquoted string
      multi_line_string #"
        hello
        world
      "#
      "a string key" true // boolean
    }
  ...

```

# ML-Specific Functionality
Below we will dive into how we can use BAML to interact with ML models -- currently focusing on LLMs.

### Define a task
Before you work with an LLM, as yourself what kind of input or output youre expecting. Is it a true or false, a list of things, or a complex type? Once you know what the inputs and outputs are you can can define a **function**.

A **function** has an **input** and an **output**. The input is the input variables, which can be a simple string like a user's question, or a complex object. The output is the shape of the object the model should return.

A **function** looks kind of like a **class** because it only defines what the inputs and outputs are, not the implementation.

```llvm
function ClassifyText {
    input string
    output MyEnum
}
```
This is like declaring a _type_ in python that matches the following function's type signature:
```python
def ClassifyText(input: str) -> MyEnum:
    ...
```

BAML allows your team to keep all your ML tasks neatly in one place with these function definitions, and ensures that all type information is transmitted to the Gloo backend at runtime, so you can query data in a strongly typed manner (more on this later, but just imagine being able to get strongly-typed pandas dataframes you can manipulate for training custom models instead of unstructured raw LLM strings).

### Implement the task
Now that we have defined our function, we need to implement it. Since we're using LLMs, we need to be able to write a prompt somewhere, and ensure that the LLM outputs the correct type we had defined for our function. But first, let's declare what LLM we want to use.

#### Declare a client
```rust
client<llm> GPT4 {
    // required
    provider baml-openai-chat
    // add whichever params you want. They're passed as-is to the LLM
    options {
      temperature 0.9
      inline_string "hi there!"
      model_name gpt-4 // an unquoted string
      multi_line_string #"
        hello
        world
      "#
    }
  }
```
Other providers are `baml-azure-chat`, `baml-anthropic` and `baml-azure-completion`.
You can also use a custom provider. See our [Anthropic Implementation](https://github.com/GlooHQ/baml/blob/canary/clients/python/baml_core/registrations/providers/anthropic_provider.py)

For a full list of providers see [ref/providers](ref/providers).

#### Define your function implementation
```rust
impl<llm, ClassifyText> {
  client GPT4
  prompt #"
    Classify this text:
    {// ... fill this out ... //}
    
  "#
}
```
Call your function in python
```python
from baml_client import baml

async def call_prompt():
    result = await baml.ClassifyText.get_impl("v1").run("hello world")
    print(result)
```


## Injecting variables
To inject a variable into a prompt, you can use the `@` symbol. This is called a **variable injection**. A prompt's variables are always accessible via \{#input\}. If the input to a prompt is only a string, you can just add **\{#input\}**
```llvm
#"
You are an assistant talking to: {#input.firstName}.
"#
```

## Injecting code

## Comments
